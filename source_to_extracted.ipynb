{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = \"./source\"\n",
    "video_file = 'nameofvideo1.mp4'\n",
    "video_name = video_file.split('.')[0]\n",
    "dataset_out_folder = './extracted'\n",
    "\n",
    "base_json_file = source_folder + '/' + video_name + '.funscript'\n",
    "surge_json_file = source_folder + '/' + video_name + '.surge.funscript'\n",
    "sway_json_file = source_folder + '/' + video_name + '.sway.funscript'\n",
    "pitch_json_file = source_folder + '/' + video_name + '.pitch.funscript'\n",
    "roll_json_file = source_folder + '/' + video_name + '.roll.funscript'\n",
    "twist_json_file = source_folder + '/' + video_name + '.twist.funscript'\n",
    "\n",
    "timestamp_file = source_folder + '/' + video_name + '.txt'\n",
    "video_file_path = source_folder + '/' + video_file\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "base_json = json.load(open(base_json_file))[\"actions\"]\n",
    "surge_json = json.load(open(surge_json_file))[\"actions\"]\n",
    "sway_json = json.load(open(sway_json_file))[\"actions\"]\n",
    "pitch_json = json.load(open(pitch_json_file))[\"actions\"]\n",
    "roll_json = json.load(open(roll_json_file))[\"actions\"]\n",
    "spin_json = json.load(open(twist_json_file))[\"actions\"]\n",
    "\n",
    "positions_data = [base_json, surge_json, sway_json, pitch_json, roll_json, spin_json]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = []\n",
    "with open(timestamp_file, 'r') as f:\n",
    "    for line in f:\n",
    "        clean_line = line.strip()\n",
    "        line_parts = clean_line.split(' ')\n",
    "        start = (int(line_parts[1].split(':')[0]) * 60 + int(line_parts[1].split(':')[1])) * 1000\n",
    "        end = (int(line_parts[2].split(':')[0]) * 60 + int(line_parts[2].split(':')[1])) * 1000\n",
    "        timestamps.append((start, end))\n",
    "print(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_file_path)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) // 2\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(video_file)\n",
    "print(video_file_path)\n",
    "print(video_name)\n",
    "print(frame_width, frame_height, fps, frame_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_data_at_time(time_, positions_):\n",
    "    pos_data = []\n",
    "    for axis in positions_:\n",
    "        # find the \"at\" values in the json that the time is between\n",
    "        previous_action = None\n",
    "        next_action = None\n",
    "        for i in range(len(axis) -1):\n",
    "            if axis[i][\"at\"] <= time_ <= axis[i+1][\"at\"]:\n",
    "                previous_action = axis[i]\n",
    "                next_action = axis[i+1]\n",
    "        if previous_action is None or next_action is None:\n",
    "            print(\"Error: time not found in data\")\n",
    "            return\n",
    "        previous_pos = previous_action[\"pos\"]\n",
    "        next_pos = next_action[\"pos\"]\n",
    "        previous_at = previous_action[\"at\"]\n",
    "        next_at = next_action[\"at\"]\n",
    "\n",
    "        time_difference = next_at - previous_at\n",
    "        pos_difference = next_pos - previous_pos\n",
    "\n",
    "        current_time_difference = time_ - previous_at\n",
    "        current_pos_difference = current_time_difference * (pos_difference / time_difference)\n",
    "        pos_data.append((previous_pos + current_pos_difference) / 100.0)\n",
    "    return pos_data\n",
    "k = 0\n",
    "frame_batch = []\n",
    "frame_batch_size = 10\n",
    "\n",
    "active_timestamp = timestamps[0] # forget if I need to fix this to loop them all\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_MSEC, active_timestamp[0])\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame_number = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "    frame_timestamp = int(cap.get(cv2.CAP_PROP_POS_MSEC))\n",
    "    #print(frame_number, frame_timestamp)\n",
    "    frame_out_file = dataset_out_folder + '/' + video_name + '_frame_' + str(frame_number) + '.jpg'\n",
    "    data_out_file = dataset_out_folder + '/' + video_name + '_frame_' + str(frame_number) + '.txt'\n",
    "    if os.path.exists(frame_out_file) and os.path.exists(data_out_file):\n",
    "        continue\n",
    "    if os.path.exists(dataset_out_folder2 + '/' + video_name + '_frame_' + str(frame_number) + '.jpg') and os.path.exists(dataset_out_folder2 + '/' + video_name + '_frame_' + str(frame_number) + '.txt'):\n",
    "        continue\n",
    "\n",
    "    if frame_timestamp > active_timestamp[1]:\n",
    "        print(\"reach end of first timestamp\")\n",
    "        break\n",
    "    frame = frame[:, frame_width:]\n",
    "    #frame = frame[frame_height // 2:, frame_width // 4: frame_width // 4 * 3]\n",
    "\n",
    "    six_axis_frame_position = get_data_at_time(frame_timestamp, positions_data)\n",
    "    \n",
    "    # with open(data_out_file, 'w') as f:\n",
    "    #     f.write(str(six_axis_frame_position).replace('[', '').replace(']', '').replace(',', '').replace(' ', '\\n'))           \n",
    "    # cv2.imwrite(frame_out_file, frame)\n",
    "\n",
    "    if not os.path.exists(frame_out_file) or not os.path.exists(data_out_file): \n",
    "        frame_batch.append((frame_out_file, frame, data_out_file, six_axis_frame_position))\n",
    "\n",
    "\n",
    "\n",
    "    if len(frame_batch) == frame_batch_size:\n",
    "        for i in range(frame_batch_size):\n",
    "            cv2.imwrite(frame_batch[i][0], frame_batch[i][1])\n",
    "            #print(frame_batch[i][0])\n",
    "            with open(frame_batch[i][2], 'w') as f:\n",
    "                f.write(str(frame_batch[i][3]).replace('[', '').replace(']', '').replace(',', '').replace(' ', '\\n'))\n",
    "                \n",
    "            k = cv2.waitKey(1) & 0xFF\n",
    "            if k == ord('q'):\n",
    "                break\n",
    "\n",
    "        frame_batch = []\n",
    "    \n",
    "    # draw a circle to visualize the position of the axises\n",
    "    # circle_x = int(six_axis_frame_position[0] * frame_width / 2)\n",
    "    # circle_y = int(six_axis_frame_position[2] * frame_height /2)\n",
    "    # frame = cv2.circle(frame, (circle_x, circle_y), 10, (0, 0, 255), -1)\n",
    "    # circle_x = int(six_axis_frame_position[3] * frame_width / 2 + frame_width / 2)\n",
    "    # circle_y = int(six_axis_frame_position[1] * frame_height  /2)\n",
    "    # frame = cv2.circle(frame, (circle_x, circle_y), 10, (0, 255, 0), -1)\n",
    "    # circle_x = int(six_axis_frame_position[4] * frame_width / 2 )\n",
    "    # circle_y = int(six_axis_frame_position[5] * frame_height  /2 + frame_height / 2)\n",
    "    # frame = cv2.circle(frame, (circle_x, circle_y), 10, (255, 0, 0), -1)\n",
    "    # frame = cv2.resize(frame, (frame_width //2, frame_height//2))\n",
    "    frame = cv2.resize(frame, (512, 512))\n",
    "    cv2.imshow('frame', frame)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
