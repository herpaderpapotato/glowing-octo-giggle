{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "import gc\n",
    "from time import time\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "policy = tf.keras.mixed_precision.Policy(\"mixed_float16\")\n",
    "tf.keras.mixed_precision.set_global_policy(policy)\n",
    "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras_cv_attention_models import efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_frames = 60\n",
    "frame_draw_size = 384\n",
    "input_shape = (image_frames, frame_draw_size, frame_draw_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_file = 'efficientnetv2-s-21k-ft1k.h5'\n",
    "if not os.path.exists(backbone_file):\n",
    "    print('downloading backbone')\n",
    "    os.system('wget https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv2_pretrained/' + backbone_file + ' -O ' + backbone_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = glob('models/*.h5')\n",
    "models.sort(key=os.path.getmtime)\n",
    "model_name = models[-1]\n",
    "print('loading model: ' + model_name)\n",
    "model = keras.models.load_model(model_name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_video = 'test.mp4'\n",
    "if not os.path.exists(test_video):\n",
    "    print('no video')\n",
    "\n",
    "start_time_minute = 31\n",
    "start_time_second = 40\n",
    "start_time = (start_time_minute*60 +start_time_second) * 1000\n",
    "\n",
    "# open the video\n",
    "cap = cv2.VideoCapture(test_video)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_MSEC, start_time)\n",
    "frames = []\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "image_size = 384\n",
    "\n",
    "featuremodel = efficientnet.EfficientNetV2S(pretrained=backbone_file,dropout=1e-6, num_classes=0, include_preprocessing = True)\n",
    "predictions = []\n",
    "frame_batch = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = frame[:, : width // 2]\n",
    "    frame = cv2.resize(frame, (image_size, image_size))\n",
    "    cv2.imshow('frame', frame)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "    frame = np.array(frame)\n",
    "    frame_features = featuremodel.predict(np.expand_dims(frame, axis=0))\n",
    "    frames.append(frame_features[0])\n",
    "    if len(frames) == 60:\n",
    "        frames = np.array(frames)\n",
    "        frame_batch.append(frames)\n",
    "        frames = []\n",
    "    if len(frame_batch) == 2:\n",
    "        frame_batch = np.array(frame_batch)\n",
    "        prediction = model.predict(frame_batch)\n",
    "        predictions.extend(prediction)\n",
    "        frame_batch = []\n",
    "    if len(predictions) > 9:\n",
    "        break\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "predictions_nparray = np.array(predictions)\n",
    "print(predictions_nparray.shape)\n",
    "new_predictions = []\n",
    "for i in range(0, len(predictions_nparray)):\n",
    "    for j in range(0, len(predictions_nparray[i]), 6):\n",
    "        new_predictions.append(predictions_nparray[i][j:j+6])\n",
    "new_predictions = np.array(new_predictions)\n",
    "print(new_predictions.shape)\n",
    "# plot the first value of each frame prediction\n",
    "plt.plot(new_predictions[:, 0])\n",
    "plt.show()    \n",
    "plt.plot(new_predictions[:, 1])\n",
    "plt.show()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.set(cv2.CAP_PROP_POS_MSEC, start_time)\n",
    "frames = []\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "print(len(new_predictions))\n",
    "frame_draw_size = 1024\n",
    "spacing = 16\n",
    "line_width = 4\n",
    "frame_for_mp4 = []\n",
    "\n",
    "while True:\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC, start_time)\n",
    "    for frame_prediction in new_predictions:\n",
    "        ret, frame = cap.read()\n",
    "        frame = frame[:, : width // 2]\n",
    "        frame = cv2.resize(frame, (frame_draw_size, frame_draw_size))\n",
    "        # frame = cv2.line(frame, (frame_draw_size//2, frame_draw_size), (frame_draw_size//2, int(frame_draw_size * frame_prediction[0])), (0, 255, 0), line_width)\n",
    "        # frame = cv2.line(frame, (frame_draw_size//2 + spacing, frame_draw_size), (frame_draw_size//2 + spacing, int(frame_draw_size * frame_prediction[1])), (0, 0, 255), line_width)\n",
    "        # frame = cv2.line(frame, (frame_draw_size//2 - spacing, frame_draw_size), (frame_draw_size//2 - spacing, int(frame_draw_size * frame_prediction[2])), (0, 0, 255), line_width)\n",
    "        # frame = cv2.line(frame, (frame_draw_size//2 + spacing * 2, frame_draw_size), (frame_draw_size//2 + spacing * 2, int(frame_draw_size * frame_prediction[3])), (0, 0, 255), line_width)\n",
    "        # frame = cv2.line(frame, (frame_draw_size//2 - spacing * 2, frame_draw_size), (frame_draw_size//2 - spacing * 2, int(frame_draw_size * frame_prediction[4])), (0, 0, 255), line_width)\n",
    "\n",
    "        # axis 0 is vertical axis and is represented by a vertical line from the bottom of the image\n",
    "        axis_0_y1 = frame_draw_size\n",
    "        axis_0_y2 = frame_draw_size - int(frame_draw_size * frame_prediction[0])\n",
    "        #frame = cv2.line(frame, (frame_draw_size//2, axis_0_y1), (frame_draw_size//2, axis_0_y2), (0, 255, 0), line_width)\n",
    "        \n",
    "        # axis 1 is depth and is the proximity to the camera and is represented by a horizontal line that grows from the center of the image\n",
    "        axis_1_x1 = frame_draw_size //2 - int(frame_draw_size * frame_prediction[1]) // 2\n",
    "        axis_1_x2 = frame_draw_size //2 + int(frame_draw_size * frame_prediction[1]) // 2\n",
    "        #frame = cv2.line(frame, (frame_draw_size //2 - int(frame_draw_size * frame_prediction[1]) // 2, frame_draw_size//2), (frame_draw_size //2 + int(frame_draw_size * frame_prediction[1]) // 2, frame_draw_size//2), (0, 0, 255), line_width)\n",
    "\n",
    "        # merged representation of axis 0 and axis 1\n",
    "        frame = cv2.line(frame, (axis_1_x1, axis_0_y2), (axis_1_x2, axis_0_y2), (0, 0, 255), line_width)\n",
    "\n",
    "        # axis 2 is horizontal axis and is represented by a vertical line that moves from left to right\n",
    "        axis_2_x1 = int(frame_draw_size * frame_prediction[2])\n",
    "        axis_2_x2 = int(frame_draw_size * frame_prediction[2])\n",
    "        #frame = cv2.line(frame, (axis_2_x1, 0), (axis_2_x2, frame_draw_size), (0, 0, 255), line_width)\n",
    "        \n",
    "        # axis 3 is pitch and represented by a vertical line that grows from the center of the image\n",
    "        axis_3_y1 = frame_draw_size //2 - int(frame_draw_size * frame_prediction[3]) // 2\n",
    "        axis_3_y2 = frame_draw_size //2 + int(frame_draw_size * frame_prediction[3]) // 2\n",
    "        #frame = cv2.line(frame, (frame_draw_size //2, axis_3_y1), (frame_draw_size //2, axis_3_y2), (0, 0, 255), line_width)\n",
    "\n",
    "        # merged representation of axis 2 and axis 3\n",
    "        frame = cv2.line(frame, (axis_2_x1, axis_3_y1), (axis_2_x2, axis_3_y2), (0, 255, 0), line_width)\n",
    "\n",
    "        # axis 4 is roll and is represented by a vertical line that tilts from left to right where 0.5 is vertical and placed in the top left quadrant\n",
    "        axis_4_x1 = int(frame_draw_size * frame_prediction[4])\n",
    "        axis_4_x2 = int(frame_draw_size - frame_draw_size * frame_prediction[4])\n",
    "        # shift it to the top left corner quadrant\n",
    "        axis_4_x1 = axis_4_x1 // 2\n",
    "        axis_4_x2 = axis_4_x2 // 2\n",
    "        axis_4_y1 = 0\n",
    "        axis_4_y2 = frame_draw_size // 2\n",
    "        frame = cv2.line(frame, (axis_4_x1, axis_4_y1), (axis_4_x2, axis_4_y2), (255, 0, 0), line_width)\n",
    "        \n",
    "        # axis 5 is twist and is represented by a horizontal line that tilts from left to right where 0.5 is vertical and placed in the top right quadrant\n",
    "        axis_5_y1 = int(frame_draw_size * frame_prediction[5])\n",
    "        axis_5_y2 = int(frame_draw_size - frame_draw_size * frame_prediction[5])\n",
    "        # shift it to the top right corner quadrant\n",
    "        axis_5_y1 = axis_5_y1 // 2\n",
    "        axis_5_y2 = axis_5_y2 // 2\n",
    "        axis_5_x1 = frame_draw_size // 2\n",
    "        axis_5_x2 = frame_draw_size\n",
    "        frame = cv2.line(frame, (axis_5_x1, axis_5_y1), (axis_5_x2, axis_5_y2), (255, 255, 0), line_width)\n",
    "\n",
    "        frame_for_mp4.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        #print(frame_prediction[0])\n",
    "        cv2.imshow('frame', frame)\n",
    "        k = cv2.waitKey(16)\n",
    "        if k == 27:\n",
    "            break\n",
    "    if k == 27:\n",
    "        break\n",
    "    break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "import imageio\n",
    "imageio.mimsave('test.mp4', frame_for_mp4, fps=60)\n",
    "\n",
    "# write gif\n",
    "import imageio\n",
    "imageio.mimsave('test.gif', frame_for_mp4, duration=1/60)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
